{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a237bab-8198-457a-953b-a63a7b32943d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš© ë””ë°”ì´ìŠ¤: cuda\n",
      "ê·¸ë¦¬ë“œ ì„œì¹˜ ë²”ìœ„:\n",
      "  hidden_size: [128, 256, 384]\n",
      "  num_layers: [3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  dropout: [0.1, 0.2, 0.3, 0.4, 0.5]\n",
      "  batch_size: [16, 32, 64, 128]\n",
      "ì´ ì¡°í•© ìˆ˜: 480\n",
      "ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...\n",
      "í›ˆë ¨ ë°ì´í„°ì…‹: 8000ê°œ\n",
      "ë°ì´í„° ì •ê·œí™” ì ìš©ë¨\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹: 2000ê°œ\n",
      "ë°ì´í„° ì •ê·œí™” ì ìš©ë¨\n",
      "ì´ 480ê°œì˜ ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n",
      "================================================================================\n",
      "\n",
      "[1/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.1, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.324170, ì‹œê°„: 109.9ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.1_b16.pth\n",
      "ì§„í–‰ë¥ : 0.2% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 877.3ë¶„\n",
      "\n",
      "[2/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.1, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.280978, ì‹œê°„: 49.3ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.1_b32.pth\n",
      "ì§„í–‰ë¥ : 0.4% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 634.3ë¶„\n",
      "\n",
      "[3/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.1, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.249380, ì‹œê°„: 27.3ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.1_b64.pth\n",
      "ì§„í–‰ë¥ : 0.6% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 494.4ë¶„\n",
      "\n",
      "[4/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.1, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.226338, ì‹œê°„: 16.5ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.1_b128.pth\n",
      "ì§„í–‰ë¥ : 0.8% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 402.8ë¶„\n",
      "\n",
      "[5/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.2, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.349509, ì‹œê°„: 91.8ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.2_b16.pth\n",
      "ì§„í–‰ë¥ : 1.0% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 466.9ë¶„\n",
      "\n",
      "[6/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.2, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.309291, ì‹œê°„: 51.8ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.2_b32.pth\n",
      "ì§„í–‰ë¥ : 1.2% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 456.5ë¶„\n",
      "\n",
      "[7/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.2, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.274168, ì‹œê°„: 27.3ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.2_b64.pth\n",
      "ì§„í–‰ë¥ : 1.5% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 421.3ë¶„\n",
      "\n",
      "[8/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.2, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.263164, ì‹œê°„: 20.0ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.2_b128.pth\n",
      "ì§„í–‰ë¥ : 1.7% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 387.5ë¶„\n",
      "\n",
      "[9/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.3, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.383491, ì‹œê°„: 99.3ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.3_b16.pth\n",
      "ì§„í–‰ë¥ : 1.9% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 430.4ë¶„\n",
      "\n",
      "[10/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.3, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.323767, ì‹œê°„: 49.0ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.3_b32.pth\n",
      "ì§„í–‰ë¥ : 2.1% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 424.9ë¶„\n",
      "\n",
      "[11/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.3, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.313448, ì‹œê°„: 27.3ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.3_b64.pth\n",
      "ì§„í–‰ë¥ : 2.3% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 404.9ë¶„\n",
      "\n",
      "[12/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.3, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.300636, ì‹œê°„: 18.0ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.3_b128.pth\n",
      "ì§„í–‰ë¥ : 2.5% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 382.1ë¶„\n",
      "\n",
      "[13/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.4, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.413828, ì‹œê°„: 93.8ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.4_b16.pth\n",
      "ì§„í–‰ë¥ : 2.7% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 408.1ë¶„\n",
      "\n",
      "[14/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.4, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.370542, ì‹œê°„: 49.2ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.4_b32.pth\n",
      "ì§„í–‰ë¥ : 2.9% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 405.4ë¶„\n",
      "\n",
      "[15/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.4, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.338330, ì‹œê°„: 30.8ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.4_b64.pth\n",
      "ì§„í–‰ë¥ : 3.1% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 393.5ë¶„\n",
      "\n",
      "[16/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.4, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.317612, ì‹œê°„: 16.6ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.4_b128.pth\n",
      "ì§„í–‰ë¥ : 3.3% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 376.2ë¶„\n",
      "\n",
      "[17/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.5, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.441018, ì‹œê°„: 108.1ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.5_b16.pth\n",
      "ì§„í–‰ë¥ : 3.5% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 402.4ë¶„\n",
      "\n",
      "[18/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.5, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.406034, ì‹œê°„: 57.2ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.5_b32.pth\n",
      "ì§„í–‰ë¥ : 3.8% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 403.7ë¶„\n",
      "\n",
      "[19/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.5, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.382915, ì‹œê°„: 27.3ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.5_b64.pth\n",
      "ì§„í–‰ë¥ : 4.0% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 392.7ë¶„\n",
      "\n",
      "[20/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.5, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.372097, ì‹œê°„: 16.5ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l3_d0.5_b128.pth\n",
      "ì§„í–‰ë¥ : 4.2% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 378.6ë¶„\n",
      "\n",
      "[21/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.1, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.272498, ì‹œê°„: 110.6ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l4_d0.1_b16.pth\n",
      "ì§„í–‰ë¥ : 4.4% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 400.0ë¶„\n",
      "\n",
      "[22/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.1, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.317615, ì‹œê°„: 127.1ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l4_d0.2_b16.pth\n",
      "ì§„í–‰ë¥ : 5.2% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 408.7ë¶„\n",
      "\n",
      "[26/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.2, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.244726, ì‹œê°„: 64.9ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l4_d0.2_b32.pth\n",
      "ì§„í–‰ë¥ : 5.4% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 411.0ë¶„\n",
      "\n",
      "[27/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.2, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.216505, ì‹œê°„: 40.0ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l4_d0.2_b64.pth\n",
      "ì§„í–‰ë¥ : 5.6% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 406.2ë¶„\n",
      "\n",
      "[28/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.2, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.205080, ì‹œê°„: 21.8ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l4_d0.2_b128.pth\n",
      "ì§„í–‰ë¥ : 5.8% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 396.6ë¶„\n",
      "\n",
      "[29/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.3, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.322151, ì‹œê°„: 116.0ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l4_d0.3_b16.pth\n",
      "ì§„í–‰ë¥ : 6.0% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 412.2ë¶„\n",
      "\n",
      "[30/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.3, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.292032, ì‹œê°„: 73.0ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l4_d0.3_b32.pth\n",
      "ì§„í–‰ë¥ : 6.2% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 415.8ë¶„\n",
      "\n",
      "[31/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.3, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.252025, ì‹œê°„: 42.9ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l4_d0.3_b64.pth\n",
      "ì§„í–‰ë¥ : 6.5% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 411.9ë¶„\n",
      "\n",
      "[32/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.3, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.257513, ì‹œê°„: 20.0ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l4_d0.3_b128.pth\n",
      "ì§„í–‰ë¥ : 6.7% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 402.8ë¶„\n",
      "\n",
      "[33/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.4, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.362216, ì‹œê°„: 116.2ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l4_d0.4_b16.pth\n",
      "ì§„í–‰ë¥ : 6.9% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 416.0ë¶„\n",
      "\n",
      "[34/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.4, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.327445, ì‹œê°„: 75.5ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l4_d0.4_b32.pth\n",
      "ì§„í–‰ë¥ : 7.1% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 419.3ë¶„\n",
      "\n",
      "[35/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.4, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.290249, ì‹œê°„: 35.3ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l4_d0.4_b64.pth\n",
      "ì§„í–‰ë¥ : 7.3% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 413.9ë¶„\n",
      "\n",
      "[36/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.4, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.294770, ì‹œê°„: 18.7ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l4_d0.4_b128.pth\n",
      "ì§„í–‰ë¥ : 7.5% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 405.4ë¶„\n",
      "\n",
      "[37/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.5, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.400721, ì‹œê°„: 107.2ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l4_d0.5_b16.pth\n",
      "ì§„í–‰ë¥ : 7.7% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 414.9ë¶„\n",
      "\n",
      "[38/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.5, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.367724, ì‹œê°„: 73.0ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l4_d0.5_b32.pth\n",
      "ì§„í–‰ë¥ : 7.9% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 417.2ë¶„\n",
      "\n",
      "[39/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.5, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.344889, ì‹œê°„: 40.6ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l4_d0.5_b64.pth\n",
      "ì§„í–‰ë¥ : 8.1% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 413.3ë¶„\n",
      "\n",
      "[40/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.5, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.332339, ì‹œê°„: 18.8ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l4_d0.5_b128.pth\n",
      "ì§„í–‰ë¥ : 8.3% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 405.5ë¶„\n",
      "\n",
      "[41/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.1, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.239605, ì‹œê°„: 130.4ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.1_b16.pth\n",
      "ì§„í–‰ë¥ : 8.5% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 417.9ë¶„\n",
      "\n",
      "[42/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.1, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.207839, ì‹œê°„: 91.2ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.1_b32.pth\n",
      "ì§„í–‰ë¥ : 8.8% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 422.9ë¶„\n",
      "\n",
      "[43/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.1, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.179257, ì‹œê°„: 48.5ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.1_b64.pth\n",
      "ì§„í–‰ë¥ : 9.0% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 420.3ë¶„\n",
      "\n",
      "[44/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.1, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.174382, ì‹œê°„: 27.8ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.1_b128.pth\n",
      "ì§„í–‰ë¥ : 9.2% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 414.4ë¶„\n",
      "\n",
      "[45/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.2, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.273789, ì‹œê°„: 134.9ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.2_b16.pth\n",
      "ì§„í–‰ë¥ : 9.4% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 426.0ë¶„\n",
      "\n",
      "[46/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.2, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.228532, ì‹œê°„: 74.6ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.2_b32.pth\n",
      "ì§„í–‰ë¥ : 9.6% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 427.5ë¶„\n",
      "\n",
      "[47/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.2, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.193025, ì‹œê°„: 36.8ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.2_b64.pth\n",
      "ì§„í–‰ë¥ : 9.8% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 423.1ë¶„\n",
      "\n",
      "[48/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.2, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.202329, ì‹œê°„: 24.8ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.2_b128.pth\n",
      "ì§„í–‰ë¥ : 10.0% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 417.1ë¶„\n",
      "\n",
      "[49/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.3, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.321259, ì‹œê°„: 123.0ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.3_b16.pth\n",
      "ì§„í–‰ë¥ : 10.2% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 425.7ë¶„\n",
      "\n",
      "[50/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.3, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.269129, ì‹œê°„: 70.7ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.3_b32.pth\n",
      "ì§„í–‰ë¥ : 10.4% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 426.3ë¶„\n",
      "\n",
      "[51/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.3, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.255348, ì‹œê°„: 40.5ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.3_b64.pth\n",
      "ì§„í–‰ë¥ : 10.6% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 422.7ë¶„\n",
      "\n",
      "[52/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.3, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.241409, ì‹œê°„: 20.6ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.3_b128.pth\n",
      "ì§„í–‰ë¥ : 10.8% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 416.4ë¶„\n",
      "\n",
      "[53/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.4, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.356090, ì‹œê°„: 151.2ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.4_b16.pth\n",
      "ì§„í–‰ë¥ : 11.0% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 427.9ë¶„\n",
      "\n",
      "[54/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.4, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.318660, ì‹œê°„: 89.6ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.4_b32.pth\n",
      "ì§„í–‰ë¥ : 11.2% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 430.8ë¶„\n",
      "\n",
      "[55/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.4, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.290959, ì‹œê°„: 38.6ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.4_b64.pth\n",
      "ì§„í–‰ë¥ : 11.5% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 426.9ë¶„\n",
      "\n",
      "[56/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.4, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.289132, ì‹œê°„: 26.6ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.4_b128.pth\n",
      "ì§„í–‰ë¥ : 11.7% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 421.7ë¶„\n",
      "\n",
      "[57/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.5, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.404386, ì‹œê°„: 135.9ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.5_b16.pth\n",
      "ì§„í–‰ë¥ : 11.9% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 430.1ë¶„\n",
      "\n",
      "[58/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.5, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.366775, ì‹œê°„: 75.1ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.5_b32.pth\n",
      "ì§„í–‰ë¥ : 12.1% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 430.8ë¶„\n",
      "\n",
      "[59/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.5, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.360186, ì‹œê°„: 41.8ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.5_b64.pth\n",
      "ì§„í–‰ë¥ : 12.3% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 427.5ë¶„\n",
      "\n",
      "[60/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.5, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.344828, ì‹œê°„: 20.6ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l5_d0.5_b128.pth\n",
      "ì§„í–‰ë¥ : 12.5% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 421.7ë¶„\n",
      "\n",
      "[61/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.1, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.250233, ì‹œê°„: 142.9ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.1_b16.pth\n",
      "ì§„í–‰ë¥ : 12.7% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 430.2ë¶„\n",
      "\n",
      "[62/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.1, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.195137, ì‹œê°„: 78.7ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.1_b32.pth\n",
      "ì§„í–‰ë¥ : 12.9% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 431.1ë¶„\n",
      "\n",
      "[63/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.1, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.176935, ì‹œê°„: 39.5ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.1_b64.pth\n",
      "ì§„í–‰ë¥ : 13.1% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 427.6ë¶„\n",
      "\n",
      "[64/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.1, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.180591, ì‹œê°„: 27.7ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.1_b128.pth\n",
      "ì§„í–‰ë¥ : 13.3% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 422.9ë¶„\n",
      "\n",
      "[65/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.2, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.279901, ì‹œê°„: 166.1ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.2_b16.pth\n",
      "ì§„í–‰ë¥ : 13.5% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 433.1ë¶„\n",
      "\n",
      "[66/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.2, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.242411, ì‹œê°„: 73.2ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.2_b32.pth\n",
      "ì§„í–‰ë¥ : 13.8% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 433.2ë¶„\n",
      "\n",
      "[67/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.2, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.203470, ì‹œê°„: 54.5ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.2_b64.pth\n",
      "ì§„í–‰ë¥ : 14.0% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 431.3ë¶„\n",
      "\n",
      "[68/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.2, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.189003, ì‹œê°„: 31.3ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.2_b128.pth\n",
      "ì§„í–‰ë¥ : 14.2% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 427.1ë¶„\n",
      "\n",
      "[69/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.3, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.326084, ì‹œê°„: 179.0ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.3_b16.pth\n",
      "ì§„í–‰ë¥ : 14.4% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 437.6ë¶„\n",
      "\n",
      "[70/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.3, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.264437, ì‹œê°„: 84.2ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.3_b32.pth\n",
      "ì§„í–‰ë¥ : 14.6% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 438.6ë¶„\n",
      "\n",
      "[71/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.3, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.240631, ì‹œê°„: 41.5ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.3_b64.pth\n",
      "ì§„í–‰ë¥ : 14.8% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 435.3ë¶„\n",
      "\n",
      "[72/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.3, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.245195, ì‹œê°„: 25.3ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.3_b128.pth\n",
      "ì§„í–‰ë¥ : 15.0% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 430.6ë¶„\n",
      "\n",
      "[73/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.4, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.369482, ì‹œê°„: 162.2ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.4_b16.pth\n",
      "ì§„í–‰ë¥ : 15.2% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 438.7ë¶„\n",
      "\n",
      "[74/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.4, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.336859, ì‹œê°„: 82.0ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.4_b32.pth\n",
      "ì§„í–‰ë¥ : 15.4% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 439.2ë¶„\n",
      "\n",
      "[75/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.4, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.314733, ì‹œê°„: 39.4ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.4_b64.pth\n",
      "ì§„í–‰ë¥ : 15.6% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 435.9ë¶„\n",
      "\n",
      "[76/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.4, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.304873, ì‹œê°„: 30.5ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.4_b128.pth\n",
      "ì§„í–‰ë¥ : 15.8% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 431.8ë¶„\n",
      "\n",
      "[77/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.5, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.413330, ì‹œê°„: 146.4ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.5_b16.pth\n",
      "ì§„í–‰ë¥ : 16.0% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 437.9ë¶„\n",
      "\n",
      "[78/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.5, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.381768, ì‹œê°„: 84.1ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.5_b32.pth\n",
      "ì§„í–‰ë¥ : 16.2% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 438.4ë¶„\n",
      "\n",
      "[79/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.5, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.364550, ì‹œê°„: 45.8ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.5_b64.pth\n",
      "ì§„í–‰ë¥ : 16.5% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 435.7ë¶„\n",
      "\n",
      "[80/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.5, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.354707, ì‹œê°„: 25.2ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l6_d0.5_b128.pth\n",
      "ì§„í–‰ë¥ : 16.7% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 431.3ë¶„\n",
      "\n",
      "[81/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.1, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.253252, ì‹œê°„: 160.9ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.1_b16.pth\n",
      "ì§„í–‰ë¥ : 16.9% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 438.1ë¶„\n",
      "\n",
      "[82/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.1, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.198627, ì‹œê°„: 89.0ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.1_b32.pth\n",
      "ì§„í–‰ë¥ : 17.1% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 438.9ë¶„\n",
      "\n",
      "[83/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.1, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.164806, ì‹œê°„: 56.9ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.1_b64.pth\n",
      "ì§„í–‰ë¥ : 17.3% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 437.0ë¶„\n",
      "\n",
      "[84/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.1, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.180504, ì‹œê°„: 25.7ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.1_b128.pth\n",
      "ì§„í–‰ë¥ : 17.5% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 432.8ë¶„\n",
      "\n",
      "[85/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.2, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.297834, ì‹œê°„: 193.9ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.2_b16.pth\n",
      "ì§„í–‰ë¥ : 17.7% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 441.6ë¶„\n",
      "\n",
      "[86/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.2, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.227291, ì‹œê°„: 93.9ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.2_b32.pth\n",
      "ì§„í–‰ë¥ : 17.9% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 442.5ë¶„\n",
      "\n",
      "[87/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.2, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.209651, ì‹œê°„: 43.9ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.2_b64.pth\n",
      "ì§„í–‰ë¥ : 18.1% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 439.6ë¶„\n",
      "\n",
      "[88/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.2, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.202676, ì‹œê°„: 25.5ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.2_b128.pth\n",
      "ì§„í–‰ë¥ : 18.3% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 435.4ë¶„\n",
      "\n",
      "[89/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.3, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.331359, ì‹œê°„: 172.2ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.3_b16.pth\n",
      "ì§„í–‰ë¥ : 18.5% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 442.1ë¶„\n",
      "\n",
      "[90/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.3, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.281655, ì‹œê°„: 90.2ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.3_b32.pth\n",
      "ì§„í–‰ë¥ : 18.8% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 442.5ë¶„\n",
      "\n",
      "[91/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.3, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.266957, ì‹œê°„: 51.8ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.3_b64.pth\n",
      "ì§„í–‰ë¥ : 19.0% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 440.2ë¶„\n",
      "\n",
      "[92/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.3, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.268888, ì‹œê°„: 25.5ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.3_b128.pth\n",
      "ì§„í–‰ë¥ : 19.2% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 436.1ë¶„\n",
      "\n",
      "[93/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.4, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.384661, ì‹œê°„: 171.2ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.4_b16.pth\n",
      "ì§„í–‰ë¥ : 19.4% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 442.2ë¶„\n",
      "\n",
      "[94/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.4, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.349637, ì‹œê°„: 82.3ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.4_b32.pth\n",
      "ì§„í–‰ë¥ : 19.6% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 442.0ë¶„\n",
      "\n",
      "[95/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.4, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.311848, ì‹œê°„: 43.6ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.4_b64.pth\n",
      "ì§„í–‰ë¥ : 19.8% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 439.2ë¶„\n",
      "\n",
      "[96/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.4, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.322671, ì‹œê°„: 25.2ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.4_b128.pth\n",
      "ì§„í–‰ë¥ : 20.0% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 435.1ë¶„\n",
      "\n",
      "[97/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.5, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.446151, ì‹œê°„: 158.0ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.5_b16.pth\n",
      "ì§„í–‰ë¥ : 20.2% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 439.9ë¶„\n",
      "\n",
      "[98/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.5, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.416826, ì‹œê°„: 87.7ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.5_b32.pth\n",
      "ì§„í–‰ë¥ : 20.4% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 440.0ë¶„\n",
      "\n",
      "[99/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.5, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.372168, ì‹œê°„: 55.6ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.5_b64.pth\n",
      "ì§„í–‰ë¥ : 20.6% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 438.0ë¶„\n",
      "\n",
      "[100/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.5, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.377959, ì‹œê°„: 25.3ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l7_d0.5_b128.pth\n",
      "ì§„í–‰ë¥ : 20.8% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 434.1ë¶„\n",
      "\n",
      "[101/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.1, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.277174, ì‹œê°„: 173.8ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l8_d0.1_b16.pth\n",
      "ì§„í–‰ë¥ : 21.0% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 439.5ë¶„\n",
      "\n",
      "[102/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.1, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.191964, ì‹œê°„: 89.5ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l8_d0.1_b32.pth\n",
      "ì§„í–‰ë¥ : 21.2% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 439.6ë¶„\n",
      "\n",
      "[103/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.1, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.179860, ì‹œê°„: 46.3ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l8_d0.1_b64.pth\n",
      "ì§„í–‰ë¥ : 21.5% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 437.0ë¶„\n",
      "\n",
      "[104/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.1, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.167754, ì‹œê°„: 26.5ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l8_d0.1_b128.pth\n",
      "ì§„í–‰ë¥ : 21.7% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 433.3ë¶„\n",
      "\n",
      "[105/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.2, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.309597, ì‹œê°„: 220.7ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l8_d0.2_b16.pth\n",
      "ì§„í–‰ë¥ : 21.9% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 441.1ë¶„\n",
      "\n",
      "[106/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.2, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.253766, ì‹œê°„: 103.8ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l8_d0.2_b32.pth\n",
      "ì§„í–‰ë¥ : 22.1% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 441.9ë¶„\n",
      "\n",
      "[107/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.2, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.233992, ì‹œê°„: 56.9ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l8_d0.2_b64.pth\n",
      "ì§„í–‰ë¥ : 22.3% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 439.9ë¶„\n",
      "\n",
      "[108/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.2, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.204667, ì‹œê°„: 29.1ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l8_d0.2_b128.pth\n",
      "ì§„í–‰ë¥ : 22.5% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 436.4ë¶„\n",
      "\n",
      "[109/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.3, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.350341, ì‹œê°„: 193.7ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l8_d0.3_b16.pth\n",
      "ì§„í–‰ë¥ : 22.7% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 442.2ë¶„\n",
      "\n",
      "[110/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.3, Batch Size: 32\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.305552, ì‹œê°„: 131.5ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l8_d0.3_b32.pth\n",
      "ì§„í–‰ë¥ : 22.9% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 444.3ë¶„\n",
      "\n",
      "[111/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.3, Batch Size: 64\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.286052, ì‹œê°„: 68.8ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l8_d0.3_b64.pth\n",
      "ì§„í–‰ë¥ : 23.1% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 443.0ë¶„\n",
      "\n",
      "[112/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.3, Batch Size: 128\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.296499, ì‹œê°„: 37.5ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l8_d0.3_b128.pth\n",
      "ì§„í–‰ë¥ : 23.3% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 439.9ë¶„\n",
      "\n",
      "[113/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.4, Batch Size: 16\n",
      "âœ“ ì™„ë£Œ - Test Loss: 0.401403, ì‹œê°„: 180.4ì´ˆ\n",
      "  ëª¨ë¸ ì €ì¥: model_h128_l8_d0.4_b16.pth\n",
      "ì§„í–‰ë¥ : 23.5% | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 444.6ë¶„\n",
      "\n",
      "[114/480] í…ŒìŠ¤íŠ¸ ì¤‘...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.4, Batch Size: 32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 492\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mê·¸ë¦¬ë“œ ì„œì¹˜ ì™„ë£Œ! ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ğŸ¯\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 492\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 472\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤í–‰\u001b[39;00m\n\u001b[1;32m    471\u001b[0m trainer \u001b[38;5;241m=\u001b[39m GridSearchTrainer(data_file, device)\n\u001b[0;32m--> 472\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_ranges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.008\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# ê²°ê³¼ ì €ì¥ ë° ë¶„ì„\u001b[39;00m\n\u001b[1;32m    475\u001b[0m results_df \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39msave_results_table(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolynomial_grid_search_results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 274\u001b[0m, in \u001b[0;36mGridSearchTrainer.grid_search\u001b[0;34m(self, config_ranges, epochs, lr)\u001b[0m\n\u001b[1;32m    271\u001b[0m config_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_single_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     config_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m config_start_time\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# ê²°ê³¼ ì €ì¥\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 214\u001b[0m, in \u001b[0;36mGridSearchTrainer.train_single_config\u001b[0;34m(self, hidden_size, num_layers, dropout, batch_size, epochs, lr)\u001b[0m\n\u001b[1;32m    212\u001b[0m pred_roots \u001b[38;5;241m=\u001b[39m model(coeffs)\n\u001b[1;32m    213\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomplex_aware_loss(pred_roots, roots)\n\u001b[0;32m--> 214\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m    216\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "\n",
    "class PolynomialDataset(Dataset):\n",
    "    def __init__(self, data_file, train=True, train_ratio=0.8, normalize=True):\n",
    "        \"\"\"\n",
    "        ì €ì¥ëœ ë°ì´í„° íŒŒì¼ë¡œë¶€í„° Dataset ìƒì„±\n",
    "        \n",
    "        Args:\n",
    "            data_file: ë°ì´í„° íŒŒì¼ ê²½ë¡œ (.json ë˜ëŠ” .pkl)\n",
    "            train: Trueë©´ í›ˆë ¨ìš©, Falseë©´ í…ŒìŠ¤íŠ¸ìš©\n",
    "            train_ratio: í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í•  ë¹„ìœ¨\n",
    "            normalize: ë°ì´í„° ì •ê·œí™” ì—¬ë¶€\n",
    "        \"\"\"\n",
    "        self.data = self.load_data(data_file)\n",
    "        self.normalize = normalize\n",
    "        self.coeffs, self.roots = self.prepare_data()\n",
    "        \n",
    "        # ì •ê·œí™” íŒŒë¼ë¯¸í„° ì €ì¥\n",
    "        if normalize:\n",
    "            self.coeff_mean = np.mean(self.coeffs, axis=0)\n",
    "            self.coeff_std = np.std(self.coeffs, axis=0) + 1e-8\n",
    "            self.root_mean = np.mean(self.roots, axis=0)\n",
    "            self.root_std = np.std(self.roots, axis=0) + 1e-8\n",
    "            \n",
    "            # ì •ê·œí™” ì ìš©\n",
    "            self.coeffs = (self.coeffs - self.coeff_mean) / self.coeff_std\n",
    "            self.roots = (self.roots - self.root_mean) / self.root_std\n",
    "        \n",
    "        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
    "        train_coeffs, test_coeffs, train_roots, test_roots = train_test_split(\n",
    "            self.coeffs, self.roots, train_size=train_ratio, random_state=42\n",
    "        )\n",
    "        \n",
    "        if train:\n",
    "            self.coeffs = train_coeffs\n",
    "            self.roots = train_roots\n",
    "        else:\n",
    "            self.coeffs = test_coeffs\n",
    "            self.roots = test_roots\n",
    "        \n",
    "        print(f\"{'í›ˆë ¨' if train else 'í…ŒìŠ¤íŠ¸'} ë°ì´í„°ì…‹: {len(self.coeffs)}ê°œ\")\n",
    "        if normalize:\n",
    "            print(f\"ë°ì´í„° ì •ê·œí™” ì ìš©ë¨\")\n",
    "    \n",
    "    def load_data(self, filename):\n",
    "        \"\"\"ë°ì´í„° íŒŒì¼ ë¡œë“œ\"\"\"\n",
    "        if filename.endswith('.json'):\n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        elif filename.endswith('.pkl'):\n",
    "            with open(filename, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        else:\n",
    "            raise ValueError(\"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. (.json ë˜ëŠ” .pkl ì‚¬ìš©)\")\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        \"\"\"ë°ì´í„°ë¥¼ í•™ìŠµìš© í˜•íƒœë¡œ ë³€í™˜\"\"\"\n",
    "        coeffs = []\n",
    "        roots = []\n",
    "        \n",
    "        for item in self.data:\n",
    "            coeffs.append(item['coefficients'])\n",
    "            \n",
    "            # ê·¼ ë°ì´í„° í˜•ì‹ í™•ì¸ ë° ë³€í™˜\n",
    "            item_roots = item['roots']\n",
    "            \n",
    "            if isinstance(item_roots[0], list):\n",
    "                # [[ì‹¤ìˆ˜ë¶€, í—ˆìˆ˜ë¶€], ...] í˜•íƒœë¥¼ [ì‹¤ìˆ˜ë¶€1, í—ˆìˆ˜ë¶€1, ...] í˜•íƒœë¡œ í‰íƒ„í™”\n",
    "                flattened_roots = []\n",
    "                for root in item_roots:\n",
    "                    flattened_roots.extend(root)\n",
    "                roots.append(flattened_roots)\n",
    "            else:\n",
    "                # ì´ë¯¸ [ì‹¤ìˆ˜ë¶€1, í—ˆìˆ˜ë¶€1, ...] í˜•íƒœ\n",
    "                roots.append(item_roots)\n",
    "        \n",
    "        return np.array(coeffs, dtype=np.float32), np.array(roots, dtype=np.float32)\n",
    "    \n",
    "    def denormalize_roots(self, normalized_roots):\n",
    "        \"\"\"ê·¼ì„ ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ë˜ëŒë¦¬ê¸°\"\"\"\n",
    "        if self.normalize and hasattr(self, 'root_mean'):\n",
    "            return normalized_roots * self.root_std + self.root_mean\n",
    "        return normalized_roots\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.coeffs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.coeffs[idx]), torch.FloatTensor(self.roots[idx])\n",
    "\n",
    "class OptimizedPolynomialRootNet(nn.Module):\n",
    "    \"\"\"ê²½ëŸ‰í™”ëœ íš¨ìœ¨ì ì¸ ë‹¤í•­ì‹ ê·¼ ì°¾ê¸° ë„¤íŠ¸ì›Œí¬\"\"\"\n",
    "    def __init__(self, input_size=6, output_size=10, hidden_size=512, num_layers=4, dropout=0.3):\n",
    "        super(OptimizedPolynomialRootNet, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        current_size = input_size\n",
    "        \n",
    "        # ì²« ë²ˆì§¸ ì¸µ\n",
    "        layers.extend([\n",
    "            nn.Linear(current_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Dropout(dropout)\n",
    "        ])\n",
    "        current_size = hidden_size\n",
    "        \n",
    "        # ì¤‘ê°„ ì¸µë“¤ (ì ì§„ì  í¬ê¸° ê°ì†Œ)\n",
    "        for i in range(num_layers - 2):\n",
    "            next_size = hidden_size // (2 ** (i + 1))\n",
    "            next_size = max(next_size, 64)  # ìµœì†Œ 64ê°œ ë‰´ëŸ°\n",
    "            \n",
    "            layers.extend([\n",
    "                nn.Linear(current_size, next_size),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(next_size),\n",
    "                nn.Dropout(dropout * 0.8)  # ì ì§„ì ìœ¼ë¡œ ë“œë¡­ì•„ì›ƒ ê°ì†Œ\n",
    "            ])\n",
    "            current_size = next_size\n",
    "        \n",
    "        # ì¶œë ¥ì¸µ\n",
    "        layers.append(nn.Linear(current_size, output_size))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            nn.init.constant_(module.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class GridSearchTrainer:\n",
    "    def __init__(self, data_file, device='cpu'):\n",
    "        self.data_file = data_file\n",
    "        self.device = device\n",
    "        self.results = []\n",
    "        \n",
    "        # ë°ì´í„°ì…‹ í•œ ë²ˆë§Œ ë¡œë“œ (ë§¤ë²ˆ ìƒˆë¡œ ë¡œë“œí•˜ë©´ ì‹œê°„ ì†Œìš”)\n",
    "        print(\"ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...\")\n",
    "        self.train_dataset = PolynomialDataset(data_file, train=True, normalize=True)\n",
    "        self.test_dataset = PolynomialDataset(data_file, train=False, normalize=True)\n",
    "        \n",
    "    def complex_aware_loss(self, pred_roots, true_roots, alpha=0.3):\n",
    "        \"\"\"ë³µì†Œìˆ˜ ê·¼ì„ ê³ ë ¤í•œ ì†ì‹¤ í•¨ìˆ˜\"\"\"\n",
    "        mse_loss = nn.MSELoss()(pred_roots, true_roots)\n",
    "        \n",
    "        pred_real = pred_roots[:, 0::2]\n",
    "        pred_imag = pred_roots[:, 1::2]\n",
    "        true_real = true_roots[:, 0::2]\n",
    "        true_imag = true_roots[:, 1::2]\n",
    "        \n",
    "        pred_magnitude = torch.sqrt(pred_real**2 + pred_imag**2)\n",
    "        true_magnitude = torch.sqrt(true_real**2 + true_imag**2)\n",
    "        magnitude_loss = nn.MSELoss()(pred_magnitude, true_magnitude)\n",
    "        \n",
    "        return (1 - alpha) * mse_loss + alpha * magnitude_loss\n",
    "    \n",
    "    def train_single_config(self, hidden_size, num_layers, dropout, batch_size, epochs=80, lr=0.008):\n",
    "        \"\"\"ë‹¨ì¼ êµ¬ì„±ìœ¼ë¡œ ëª¨ë¸ í›ˆë ¨\"\"\"\n",
    "        \n",
    "        # ë°ì´í„° ë¡œë” ìƒì„±\n",
    "        train_loader = DataLoader(self.train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "        test_loader = DataLoader(self.test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        # ëª¨ë¸ ìƒì„±\n",
    "        model = OptimizedPolynomialRootNet(\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout\n",
    "        ).to(self.device)\n",
    "        \n",
    "        param_count = sum(p.numel() for p in model.parameters())\n",
    "        \n",
    "        # ì˜µí‹°ë§ˆì´ì € ë° ìŠ¤ì¼€ì¤„ëŸ¬\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=10\n",
    "        )\n",
    "        \n",
    "        # í›ˆë ¨ ê¸°ë¡\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        best_test_loss = float('inf')\n",
    "        \n",
    "        # í›ˆë ¨ ë£¨í”„\n",
    "        for epoch in range(epochs):\n",
    "            # í›ˆë ¨\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for coeffs, roots in train_loader:\n",
    "                coeffs, roots = coeffs.to(self.device), roots.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                pred_roots = model(coeffs)\n",
    "                loss = self.complex_aware_loss(pred_roots, roots)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            \n",
    "            # í…ŒìŠ¤íŠ¸\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for coeffs, roots in test_loader:\n",
    "                    coeffs, roots = coeffs.to(self.device), roots.to(self.device)\n",
    "                    pred_roots = model(coeffs)\n",
    "                    loss = self.complex_aware_loss(pred_roots, roots)\n",
    "                    test_loss += loss.item()\n",
    "            \n",
    "            test_loss /= len(test_loader)\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            scheduler.step(test_loss)\n",
    "            \n",
    "            if test_loss < best_test_loss:\n",
    "                best_test_loss = test_loss\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'param_count': param_count,\n",
    "            'best_test_loss': best_test_loss,\n",
    "            'final_train_loss': train_losses[-1],\n",
    "            'train_losses': train_losses,\n",
    "            'test_losses': test_losses\n",
    "        }\n",
    "    \n",
    "    def grid_search(self, config_ranges, epochs=80, lr=0.008):\n",
    "        \"\"\"ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤í–‰\"\"\"\n",
    "        \n",
    "        # ëª¨ë“  ì¡°í•© ìƒì„±\n",
    "        combinations = list(itertools.product(\n",
    "            config_ranges['hidden_size'],\n",
    "            config_ranges['num_layers'],\n",
    "            config_ranges['dropout'],\n",
    "            config_ranges['batch_size']\n",
    "        ))\n",
    "        \n",
    "        total_combinations = len(combinations)\n",
    "        print(f\"ì´ {total_combinations}ê°œì˜ ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i, (hidden_size, num_layers, dropout, batch_size) in enumerate(combinations):\n",
    "            print(f\"\\n[{i+1}/{total_combinations}] í…ŒìŠ¤íŠ¸ ì¤‘...\")\n",
    "            print(f\"Hidden Size: {hidden_size}, Layers: {num_layers}, Dropout: {dropout}, Batch Size: {batch_size}\")\n",
    "            \n",
    "            config_start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                result = self.train_single_config(\n",
    "                    hidden_size=hidden_size,\n",
    "                    num_layers=num_layers,\n",
    "                    dropout=dropout,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    lr=lr\n",
    "                )\n",
    "                \n",
    "                config_time = time.time() - config_start_time\n",
    "                \n",
    "                # ê²°ê³¼ ì €ì¥\n",
    "                config_result = {\n",
    "                    'config_id': i + 1,\n",
    "                    'hidden_size': hidden_size,\n",
    "                    'num_layers': num_layers,\n",
    "                    'dropout': dropout,\n",
    "                    'batch_size': batch_size,\n",
    "                    'param_count': result['param_count'],\n",
    "                    'best_test_loss': result['best_test_loss'],\n",
    "                    'final_train_loss': result['final_train_loss'],\n",
    "                    'training_time': config_time,\n",
    "                    'model_state_dict': result['model'].state_dict(),\n",
    "                    'train_losses': result['train_losses'],\n",
    "                    'test_losses': result['test_losses']\n",
    "                }\n",
    "                \n",
    "                self.results.append(config_result)\n",
    "                \n",
    "                # ëª¨ë¸ ì €ì¥\n",
    "                model_filename = f\"model_h{hidden_size}_l{num_layers}_d{dropout:.1f}_b{batch_size}.pth\"\n",
    "                torch.save({\n",
    "                    'model_state_dict': result['model'].state_dict(),\n",
    "                    'config': config_result,\n",
    "                    'model_architecture': {\n",
    "                        'hidden_size': hidden_size,\n",
    "                        'num_layers': num_layers,\n",
    "                        'dropout': dropout\n",
    "                    }\n",
    "                }, model_filename)\n",
    "                \n",
    "                print(f\"âœ“ ì™„ë£Œ - Test Loss: {result['best_test_loss']:.6f}, ì‹œê°„: {config_time:.1f}ì´ˆ\")\n",
    "                print(f\"  ëª¨ë¸ ì €ì¥: {model_filename}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âœ— ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "                continue\n",
    "            \n",
    "            # ì§„í–‰ë¥  ë° ì˜ˆìƒ ì‹œê°„\n",
    "            elapsed_time = time.time() - start_time\n",
    "            avg_time_per_config = elapsed_time / (i + 1)\n",
    "            remaining_configs = total_combinations - (i + 1)\n",
    "            estimated_remaining_time = avg_time_per_config * remaining_configs\n",
    "            \n",
    "            print(f\"ì§„í–‰ë¥ : {(i+1)/total_combinations*100:.1f}% | \"\n",
    "                  f\"ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {estimated_remaining_time/60:.1f}ë¶„\")\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\nê·¸ë¦¬ë“œ ì„œì¹˜ ì™„ë£Œ! ì´ ì‹œê°„: {total_time/3600:.2f}ì‹œê°„\")\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def save_results_table(self, filename=\"grid_search_results.csv\"):\n",
    "        \"\"\"ê²°ê³¼ë¥¼ CSV í…Œì´ë¸”ë¡œ ì €ì¥\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        # DataFrame ìƒì„±ìš© ë°ì´í„°\n",
    "        table_data = []\n",
    "        for result in self.results:\n",
    "            table_data.append({\n",
    "                'Config_ID': result['config_id'],\n",
    "                'Hidden_Size': result['hidden_size'],\n",
    "                'Num_Layers': result['num_layers'],\n",
    "                'Dropout': result['dropout'],\n",
    "                'Batch_Size': result['batch_size'],\n",
    "                'Parameters': result['param_count'],\n",
    "                'Best_Test_Loss': result['best_test_loss'],\n",
    "                'Final_Train_Loss': result['final_train_loss'],\n",
    "                'Overfitting_Gap': result['final_train_loss'] - result['best_test_loss'],\n",
    "                'Training_Time_Min': result['training_time'] / 60\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(table_data)\n",
    "        \n",
    "        # ì„±ëŠ¥ ìˆœìœ¼ë¡œ ì •ë ¬\n",
    "        df = df.sort_values('Best_Test_Loss')\n",
    "        df = df.reset_index(drop=True)\n",
    "        df['Rank'] = range(1, len(df) + 1)\n",
    "        \n",
    "        # CSV ì €ì¥\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"ê²°ê³¼ í…Œì´ë¸” ì €ì¥: {filename}\")\n",
    "        \n",
    "        # ìƒìœ„ 10ê°œ ê²°ê³¼ ì¶œë ¥\n",
    "        print(\"\\n=== ìƒìœ„ 10ê°œ ê²°ê³¼ ===\")\n",
    "        print(df.head(10).to_string(index=False))\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def plot_results_analysis(self):\n",
    "        \"\"\"ê²°ê³¼ ë¶„ì„ ì‹œê°í™”\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"ë¶„ì„í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        \n",
    "        # ë°ì´í„° ì¤€ë¹„\n",
    "        hidden_sizes = [r['hidden_size'] for r in self.results]\n",
    "        num_layers = [r['num_layers'] for r in self.results]\n",
    "        dropouts = [r['dropout'] for r in self.results]\n",
    "        batch_sizes = [r['batch_size'] for r in self.results]\n",
    "        test_losses = [r['best_test_loss'] for r in self.results]\n",
    "        param_counts = [r['param_count'] for r in self.results]\n",
    "        \n",
    "        # 1. Hidden Size vs Test Loss\n",
    "        axes[0,0].scatter(hidden_sizes, test_losses, alpha=0.7)\n",
    "        axes[0,0].set_xlabel('Hidden Size')\n",
    "        axes[0,0].set_ylabel('Best Test Loss')\n",
    "        axes[0,0].set_title('Hidden Size vs Performance')\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Num Layers vs Test Loss\n",
    "        axes[0,1].scatter(num_layers, test_losses, alpha=0.7)\n",
    "        axes[0,1].set_xlabel('Number of Layers')\n",
    "        axes[0,1].set_ylabel('Best Test Loss')\n",
    "        axes[0,1].set_title('Network Depth vs Performance')\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Dropout vs Test Loss\n",
    "        axes[0,2].scatter(dropouts, test_losses, alpha=0.7)\n",
    "        axes[0,2].set_xlabel('Dropout Rate')\n",
    "        axes[0,2].set_ylabel('Best Test Loss')\n",
    "        axes[0,2].set_title('Dropout Rate vs Performance')\n",
    "        axes[0,2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Batch Size vs Test Loss\n",
    "        axes[1,0].scatter(batch_sizes, test_losses, alpha=0.7)\n",
    "        axes[1,0].set_xlabel('Batch Size')\n",
    "        axes[1,0].set_ylabel('Best Test Loss')\n",
    "        axes[1,0].set_title('Batch Size vs Performance')\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. Parameters vs Test Loss\n",
    "        axes[1,1].scatter(param_counts, test_losses, alpha=0.7)\n",
    "        axes[1,1].set_xlabel('Number of Parameters')\n",
    "        axes[1,1].set_ylabel('Best Test Loss')\n",
    "        axes[1,1].set_title('Model Size vs Performance')\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 6. Best configurations íˆíŠ¸ë§µ\n",
    "        best_configs = sorted(self.results, key=lambda x: x['best_test_loss'])[:10]\n",
    "        config_names = [f\"H{c['hidden_size']}_L{c['num_layers']}_D{c['dropout']:.1f}_B{c['batch_size']}\" \n",
    "                       for c in best_configs]\n",
    "        losses = [c['best_test_loss'] for c in best_configs]\n",
    "        \n",
    "        axes[1,2].barh(range(len(config_names)), losses)\n",
    "        axes[1,2].set_yticks(range(len(config_names)))\n",
    "        axes[1,2].set_yticklabels(config_names, fontsize=8)\n",
    "        axes[1,2].set_xlabel('Best Test Loss')\n",
    "        axes[1,2].set_title('Top 10 Configurations')\n",
    "        axes[1,2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('grid_search_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "def main():\n",
    "    # ì„¤ì •\n",
    "    data_file = \"polynomial_dataset_sorted.json\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n",
    "    \n",
    "    if not os.path.exists(data_file):\n",
    "        print(f\"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_file}\")\n",
    "        return\n",
    "    \n",
    "    # ê·¸ë¦¬ë“œ ì„œì¹˜ ë²”ìœ„ ì •ì˜\n",
    "    # 128*4, 128*5, 128*6, 128*7, 128*8, 128*9, 128*10, 128*11, 128*12\n",
    "    config_ranges = {\n",
    "        'hidden_size': [128*1, 128*2, 128*3],\n",
    "        'num_layers': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'dropout': [0.1, 0.2, 0.3],\n",
    "        'batch_size': [16, 32, 64, 128]\n",
    "    }\n",
    "    \n",
    "    print(\"ê·¸ë¦¬ë“œ ì„œì¹˜ ë²”ìœ„:\")\n",
    "    for key, values in config_ranges.items():\n",
    "        print(f\"  {key}: {values}\")\n",
    "    \n",
    "    total_combinations = 1\n",
    "    for values in config_ranges.values():\n",
    "        total_combinations *= len(values)\n",
    "    print(f\"ì´ ì¡°í•© ìˆ˜: {total_combinations}\")\n",
    "    \n",
    "    # ê·¸ë¦¬ë“œ ì„œì¹˜ ì‹¤í–‰\n",
    "    trainer = GridSearchTrainer(data_file, device)\n",
    "    results = trainer.grid_search(config_ranges, epochs=80, lr=0.008)\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥ ë° ë¶„ì„\n",
    "    results_df = trainer.save_results_table(\"polynomial_grid_search_results.csv\")\n",
    "    trainer.plot_results_analysis()\n",
    "    \n",
    "    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì •ë³´\n",
    "    if results:\n",
    "        best_result = min(results, key=lambda x: x['best_test_loss'])\n",
    "        print(f\"\\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸:\")\n",
    "        print(f\"  Hidden Size: {best_result['hidden_size']}\")\n",
    "        print(f\"  Num Layers: {best_result['num_layers']}\")\n",
    "        print(f\"  Dropout: {best_result['dropout']}\")\n",
    "        print(f\"  Batch Size: {best_result['batch_size']}\")\n",
    "        print(f\"  Best Test Loss: {best_result['best_test_loss']:.6f}\")\n",
    "        print(f\"  Parameters: {best_result['param_count']:,}\")\n",
    "    \n",
    "    print(\"\\nê·¸ë¦¬ë“œ ì„œì¹˜ ì™„ë£Œ! ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ğŸ¯\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a5dc2-2a38-495d-979b-0b7fbf9a42e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
