{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a237bab-8198-457a-953b-a63a7b32943d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 디바이스: cuda\n",
      "그리드 서치 범위:\n",
      "  hidden_size: [128, 256, 384]\n",
      "  num_layers: [3, 4, 5, 6, 7, 8, 9, 10]\n",
      "  dropout: [0.1, 0.2, 0.3, 0.4, 0.5]\n",
      "  batch_size: [16, 32, 64, 128]\n",
      "총 조합 수: 480\n",
      "데이터셋 로딩 중...\n",
      "훈련 데이터셋: 8000개\n",
      "데이터 정규화 적용됨\n",
      "테스트 데이터셋: 2000개\n",
      "데이터 정규화 적용됨\n",
      "총 480개의 조합을 테스트합니다.\n",
      "================================================================================\n",
      "\n",
      "[1/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.1, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.324170, 시간: 109.9초\n",
      "  모델 저장: model_h128_l3_d0.1_b16.pth\n",
      "진행률: 0.2% | 예상 남은 시간: 877.3분\n",
      "\n",
      "[2/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.1, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.280978, 시간: 49.3초\n",
      "  모델 저장: model_h128_l3_d0.1_b32.pth\n",
      "진행률: 0.4% | 예상 남은 시간: 634.3분\n",
      "\n",
      "[3/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.1, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.249380, 시간: 27.3초\n",
      "  모델 저장: model_h128_l3_d0.1_b64.pth\n",
      "진행률: 0.6% | 예상 남은 시간: 494.4분\n",
      "\n",
      "[4/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.1, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.226338, 시간: 16.5초\n",
      "  모델 저장: model_h128_l3_d0.1_b128.pth\n",
      "진행률: 0.8% | 예상 남은 시간: 402.8분\n",
      "\n",
      "[5/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.2, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.349509, 시간: 91.8초\n",
      "  모델 저장: model_h128_l3_d0.2_b16.pth\n",
      "진행률: 1.0% | 예상 남은 시간: 466.9분\n",
      "\n",
      "[6/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.2, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.309291, 시간: 51.8초\n",
      "  모델 저장: model_h128_l3_d0.2_b32.pth\n",
      "진행률: 1.2% | 예상 남은 시간: 456.5분\n",
      "\n",
      "[7/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.2, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.274168, 시간: 27.3초\n",
      "  모델 저장: model_h128_l3_d0.2_b64.pth\n",
      "진행률: 1.5% | 예상 남은 시간: 421.3분\n",
      "\n",
      "[8/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.2, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.263164, 시간: 20.0초\n",
      "  모델 저장: model_h128_l3_d0.2_b128.pth\n",
      "진행률: 1.7% | 예상 남은 시간: 387.5분\n",
      "\n",
      "[9/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.3, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.383491, 시간: 99.3초\n",
      "  모델 저장: model_h128_l3_d0.3_b16.pth\n",
      "진행률: 1.9% | 예상 남은 시간: 430.4분\n",
      "\n",
      "[10/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.3, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.323767, 시간: 49.0초\n",
      "  모델 저장: model_h128_l3_d0.3_b32.pth\n",
      "진행률: 2.1% | 예상 남은 시간: 424.9분\n",
      "\n",
      "[11/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.3, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.313448, 시간: 27.3초\n",
      "  모델 저장: model_h128_l3_d0.3_b64.pth\n",
      "진행률: 2.3% | 예상 남은 시간: 404.9분\n",
      "\n",
      "[12/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.3, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.300636, 시간: 18.0초\n",
      "  모델 저장: model_h128_l3_d0.3_b128.pth\n",
      "진행률: 2.5% | 예상 남은 시간: 382.1분\n",
      "\n",
      "[13/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.4, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.413828, 시간: 93.8초\n",
      "  모델 저장: model_h128_l3_d0.4_b16.pth\n",
      "진행률: 2.7% | 예상 남은 시간: 408.1분\n",
      "\n",
      "[14/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.4, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.370542, 시간: 49.2초\n",
      "  모델 저장: model_h128_l3_d0.4_b32.pth\n",
      "진행률: 2.9% | 예상 남은 시간: 405.4분\n",
      "\n",
      "[15/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.4, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.338330, 시간: 30.8초\n",
      "  모델 저장: model_h128_l3_d0.4_b64.pth\n",
      "진행률: 3.1% | 예상 남은 시간: 393.5분\n",
      "\n",
      "[16/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.4, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.317612, 시간: 16.6초\n",
      "  모델 저장: model_h128_l3_d0.4_b128.pth\n",
      "진행률: 3.3% | 예상 남은 시간: 376.2분\n",
      "\n",
      "[17/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.5, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.441018, 시간: 108.1초\n",
      "  모델 저장: model_h128_l3_d0.5_b16.pth\n",
      "진행률: 3.5% | 예상 남은 시간: 402.4분\n",
      "\n",
      "[18/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.5, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.406034, 시간: 57.2초\n",
      "  모델 저장: model_h128_l3_d0.5_b32.pth\n",
      "진행률: 3.8% | 예상 남은 시간: 403.7분\n",
      "\n",
      "[19/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.5, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.382915, 시간: 27.3초\n",
      "  모델 저장: model_h128_l3_d0.5_b64.pth\n",
      "진행률: 4.0% | 예상 남은 시간: 392.7분\n",
      "\n",
      "[20/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 3, Dropout: 0.5, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.372097, 시간: 16.5초\n",
      "  모델 저장: model_h128_l3_d0.5_b128.pth\n",
      "진행률: 4.2% | 예상 남은 시간: 378.6분\n",
      "\n",
      "[21/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.1, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.272498, 시간: 110.6초\n",
      "  모델 저장: model_h128_l4_d0.1_b16.pth\n",
      "진행률: 4.4% | 예상 남은 시간: 400.0분\n",
      "\n",
      "[22/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.1, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.317615, 시간: 127.1초\n",
      "  모델 저장: model_h128_l4_d0.2_b16.pth\n",
      "진행률: 5.2% | 예상 남은 시간: 408.7분\n",
      "\n",
      "[26/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.2, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.244726, 시간: 64.9초\n",
      "  모델 저장: model_h128_l4_d0.2_b32.pth\n",
      "진행률: 5.4% | 예상 남은 시간: 411.0분\n",
      "\n",
      "[27/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.2, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.216505, 시간: 40.0초\n",
      "  모델 저장: model_h128_l4_d0.2_b64.pth\n",
      "진행률: 5.6% | 예상 남은 시간: 406.2분\n",
      "\n",
      "[28/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.2, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.205080, 시간: 21.8초\n",
      "  모델 저장: model_h128_l4_d0.2_b128.pth\n",
      "진행률: 5.8% | 예상 남은 시간: 396.6분\n",
      "\n",
      "[29/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.3, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.322151, 시간: 116.0초\n",
      "  모델 저장: model_h128_l4_d0.3_b16.pth\n",
      "진행률: 6.0% | 예상 남은 시간: 412.2분\n",
      "\n",
      "[30/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.3, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.292032, 시간: 73.0초\n",
      "  모델 저장: model_h128_l4_d0.3_b32.pth\n",
      "진행률: 6.2% | 예상 남은 시간: 415.8분\n",
      "\n",
      "[31/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.3, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.252025, 시간: 42.9초\n",
      "  모델 저장: model_h128_l4_d0.3_b64.pth\n",
      "진행률: 6.5% | 예상 남은 시간: 411.9분\n",
      "\n",
      "[32/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.3, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.257513, 시간: 20.0초\n",
      "  모델 저장: model_h128_l4_d0.3_b128.pth\n",
      "진행률: 6.7% | 예상 남은 시간: 402.8분\n",
      "\n",
      "[33/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.4, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.362216, 시간: 116.2초\n",
      "  모델 저장: model_h128_l4_d0.4_b16.pth\n",
      "진행률: 6.9% | 예상 남은 시간: 416.0분\n",
      "\n",
      "[34/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.4, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.327445, 시간: 75.5초\n",
      "  모델 저장: model_h128_l4_d0.4_b32.pth\n",
      "진행률: 7.1% | 예상 남은 시간: 419.3분\n",
      "\n",
      "[35/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.4, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.290249, 시간: 35.3초\n",
      "  모델 저장: model_h128_l4_d0.4_b64.pth\n",
      "진행률: 7.3% | 예상 남은 시간: 413.9분\n",
      "\n",
      "[36/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.4, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.294770, 시간: 18.7초\n",
      "  모델 저장: model_h128_l4_d0.4_b128.pth\n",
      "진행률: 7.5% | 예상 남은 시간: 405.4분\n",
      "\n",
      "[37/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.5, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.400721, 시간: 107.2초\n",
      "  모델 저장: model_h128_l4_d0.5_b16.pth\n",
      "진행률: 7.7% | 예상 남은 시간: 414.9분\n",
      "\n",
      "[38/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.5, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.367724, 시간: 73.0초\n",
      "  모델 저장: model_h128_l4_d0.5_b32.pth\n",
      "진행률: 7.9% | 예상 남은 시간: 417.2분\n",
      "\n",
      "[39/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.5, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.344889, 시간: 40.6초\n",
      "  모델 저장: model_h128_l4_d0.5_b64.pth\n",
      "진행률: 8.1% | 예상 남은 시간: 413.3분\n",
      "\n",
      "[40/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 4, Dropout: 0.5, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.332339, 시간: 18.8초\n",
      "  모델 저장: model_h128_l4_d0.5_b128.pth\n",
      "진행률: 8.3% | 예상 남은 시간: 405.5분\n",
      "\n",
      "[41/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.1, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.239605, 시간: 130.4초\n",
      "  모델 저장: model_h128_l5_d0.1_b16.pth\n",
      "진행률: 8.5% | 예상 남은 시간: 417.9분\n",
      "\n",
      "[42/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.1, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.207839, 시간: 91.2초\n",
      "  모델 저장: model_h128_l5_d0.1_b32.pth\n",
      "진행률: 8.8% | 예상 남은 시간: 422.9분\n",
      "\n",
      "[43/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.1, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.179257, 시간: 48.5초\n",
      "  모델 저장: model_h128_l5_d0.1_b64.pth\n",
      "진행률: 9.0% | 예상 남은 시간: 420.3분\n",
      "\n",
      "[44/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.1, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.174382, 시간: 27.8초\n",
      "  모델 저장: model_h128_l5_d0.1_b128.pth\n",
      "진행률: 9.2% | 예상 남은 시간: 414.4분\n",
      "\n",
      "[45/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.2, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.273789, 시간: 134.9초\n",
      "  모델 저장: model_h128_l5_d0.2_b16.pth\n",
      "진행률: 9.4% | 예상 남은 시간: 426.0분\n",
      "\n",
      "[46/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.2, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.228532, 시간: 74.6초\n",
      "  모델 저장: model_h128_l5_d0.2_b32.pth\n",
      "진행률: 9.6% | 예상 남은 시간: 427.5분\n",
      "\n",
      "[47/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.2, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.193025, 시간: 36.8초\n",
      "  모델 저장: model_h128_l5_d0.2_b64.pth\n",
      "진행률: 9.8% | 예상 남은 시간: 423.1분\n",
      "\n",
      "[48/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.2, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.202329, 시간: 24.8초\n",
      "  모델 저장: model_h128_l5_d0.2_b128.pth\n",
      "진행률: 10.0% | 예상 남은 시간: 417.1분\n",
      "\n",
      "[49/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.3, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.321259, 시간: 123.0초\n",
      "  모델 저장: model_h128_l5_d0.3_b16.pth\n",
      "진행률: 10.2% | 예상 남은 시간: 425.7분\n",
      "\n",
      "[50/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.3, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.269129, 시간: 70.7초\n",
      "  모델 저장: model_h128_l5_d0.3_b32.pth\n",
      "진행률: 10.4% | 예상 남은 시간: 426.3분\n",
      "\n",
      "[51/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.3, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.255348, 시간: 40.5초\n",
      "  모델 저장: model_h128_l5_d0.3_b64.pth\n",
      "진행률: 10.6% | 예상 남은 시간: 422.7분\n",
      "\n",
      "[52/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.3, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.241409, 시간: 20.6초\n",
      "  모델 저장: model_h128_l5_d0.3_b128.pth\n",
      "진행률: 10.8% | 예상 남은 시간: 416.4분\n",
      "\n",
      "[53/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.4, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.356090, 시간: 151.2초\n",
      "  모델 저장: model_h128_l5_d0.4_b16.pth\n",
      "진행률: 11.0% | 예상 남은 시간: 427.9분\n",
      "\n",
      "[54/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.4, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.318660, 시간: 89.6초\n",
      "  모델 저장: model_h128_l5_d0.4_b32.pth\n",
      "진행률: 11.2% | 예상 남은 시간: 430.8분\n",
      "\n",
      "[55/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.4, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.290959, 시간: 38.6초\n",
      "  모델 저장: model_h128_l5_d0.4_b64.pth\n",
      "진행률: 11.5% | 예상 남은 시간: 426.9분\n",
      "\n",
      "[56/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.4, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.289132, 시간: 26.6초\n",
      "  모델 저장: model_h128_l5_d0.4_b128.pth\n",
      "진행률: 11.7% | 예상 남은 시간: 421.7분\n",
      "\n",
      "[57/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.5, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.404386, 시간: 135.9초\n",
      "  모델 저장: model_h128_l5_d0.5_b16.pth\n",
      "진행률: 11.9% | 예상 남은 시간: 430.1분\n",
      "\n",
      "[58/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.5, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.366775, 시간: 75.1초\n",
      "  모델 저장: model_h128_l5_d0.5_b32.pth\n",
      "진행률: 12.1% | 예상 남은 시간: 430.8분\n",
      "\n",
      "[59/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.5, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.360186, 시간: 41.8초\n",
      "  모델 저장: model_h128_l5_d0.5_b64.pth\n",
      "진행률: 12.3% | 예상 남은 시간: 427.5분\n",
      "\n",
      "[60/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 5, Dropout: 0.5, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.344828, 시간: 20.6초\n",
      "  모델 저장: model_h128_l5_d0.5_b128.pth\n",
      "진행률: 12.5% | 예상 남은 시간: 421.7분\n",
      "\n",
      "[61/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.1, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.250233, 시간: 142.9초\n",
      "  모델 저장: model_h128_l6_d0.1_b16.pth\n",
      "진행률: 12.7% | 예상 남은 시간: 430.2분\n",
      "\n",
      "[62/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.1, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.195137, 시간: 78.7초\n",
      "  모델 저장: model_h128_l6_d0.1_b32.pth\n",
      "진행률: 12.9% | 예상 남은 시간: 431.1분\n",
      "\n",
      "[63/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.1, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.176935, 시간: 39.5초\n",
      "  모델 저장: model_h128_l6_d0.1_b64.pth\n",
      "진행률: 13.1% | 예상 남은 시간: 427.6분\n",
      "\n",
      "[64/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.1, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.180591, 시간: 27.7초\n",
      "  모델 저장: model_h128_l6_d0.1_b128.pth\n",
      "진행률: 13.3% | 예상 남은 시간: 422.9분\n",
      "\n",
      "[65/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.2, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.279901, 시간: 166.1초\n",
      "  모델 저장: model_h128_l6_d0.2_b16.pth\n",
      "진행률: 13.5% | 예상 남은 시간: 433.1분\n",
      "\n",
      "[66/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.2, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.242411, 시간: 73.2초\n",
      "  모델 저장: model_h128_l6_d0.2_b32.pth\n",
      "진행률: 13.8% | 예상 남은 시간: 433.2분\n",
      "\n",
      "[67/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.2, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.203470, 시간: 54.5초\n",
      "  모델 저장: model_h128_l6_d0.2_b64.pth\n",
      "진행률: 14.0% | 예상 남은 시간: 431.3분\n",
      "\n",
      "[68/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.2, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.189003, 시간: 31.3초\n",
      "  모델 저장: model_h128_l6_d0.2_b128.pth\n",
      "진행률: 14.2% | 예상 남은 시간: 427.1분\n",
      "\n",
      "[69/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.3, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.326084, 시간: 179.0초\n",
      "  모델 저장: model_h128_l6_d0.3_b16.pth\n",
      "진행률: 14.4% | 예상 남은 시간: 437.6분\n",
      "\n",
      "[70/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.3, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.264437, 시간: 84.2초\n",
      "  모델 저장: model_h128_l6_d0.3_b32.pth\n",
      "진행률: 14.6% | 예상 남은 시간: 438.6분\n",
      "\n",
      "[71/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.3, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.240631, 시간: 41.5초\n",
      "  모델 저장: model_h128_l6_d0.3_b64.pth\n",
      "진행률: 14.8% | 예상 남은 시간: 435.3분\n",
      "\n",
      "[72/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.3, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.245195, 시간: 25.3초\n",
      "  모델 저장: model_h128_l6_d0.3_b128.pth\n",
      "진행률: 15.0% | 예상 남은 시간: 430.6분\n",
      "\n",
      "[73/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.4, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.369482, 시간: 162.2초\n",
      "  모델 저장: model_h128_l6_d0.4_b16.pth\n",
      "진행률: 15.2% | 예상 남은 시간: 438.7분\n",
      "\n",
      "[74/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.4, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.336859, 시간: 82.0초\n",
      "  모델 저장: model_h128_l6_d0.4_b32.pth\n",
      "진행률: 15.4% | 예상 남은 시간: 439.2분\n",
      "\n",
      "[75/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.4, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.314733, 시간: 39.4초\n",
      "  모델 저장: model_h128_l6_d0.4_b64.pth\n",
      "진행률: 15.6% | 예상 남은 시간: 435.9분\n",
      "\n",
      "[76/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.4, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.304873, 시간: 30.5초\n",
      "  모델 저장: model_h128_l6_d0.4_b128.pth\n",
      "진행률: 15.8% | 예상 남은 시간: 431.8분\n",
      "\n",
      "[77/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.5, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.413330, 시간: 146.4초\n",
      "  모델 저장: model_h128_l6_d0.5_b16.pth\n",
      "진행률: 16.0% | 예상 남은 시간: 437.9분\n",
      "\n",
      "[78/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.5, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.381768, 시간: 84.1초\n",
      "  모델 저장: model_h128_l6_d0.5_b32.pth\n",
      "진행률: 16.2% | 예상 남은 시간: 438.4분\n",
      "\n",
      "[79/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.5, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.364550, 시간: 45.8초\n",
      "  모델 저장: model_h128_l6_d0.5_b64.pth\n",
      "진행률: 16.5% | 예상 남은 시간: 435.7분\n",
      "\n",
      "[80/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 6, Dropout: 0.5, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.354707, 시간: 25.2초\n",
      "  모델 저장: model_h128_l6_d0.5_b128.pth\n",
      "진행률: 16.7% | 예상 남은 시간: 431.3분\n",
      "\n",
      "[81/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.1, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.253252, 시간: 160.9초\n",
      "  모델 저장: model_h128_l7_d0.1_b16.pth\n",
      "진행률: 16.9% | 예상 남은 시간: 438.1분\n",
      "\n",
      "[82/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.1, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.198627, 시간: 89.0초\n",
      "  모델 저장: model_h128_l7_d0.1_b32.pth\n",
      "진행률: 17.1% | 예상 남은 시간: 438.9분\n",
      "\n",
      "[83/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.1, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.164806, 시간: 56.9초\n",
      "  모델 저장: model_h128_l7_d0.1_b64.pth\n",
      "진행률: 17.3% | 예상 남은 시간: 437.0분\n",
      "\n",
      "[84/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.1, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.180504, 시간: 25.7초\n",
      "  모델 저장: model_h128_l7_d0.1_b128.pth\n",
      "진행률: 17.5% | 예상 남은 시간: 432.8분\n",
      "\n",
      "[85/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.2, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.297834, 시간: 193.9초\n",
      "  모델 저장: model_h128_l7_d0.2_b16.pth\n",
      "진행률: 17.7% | 예상 남은 시간: 441.6분\n",
      "\n",
      "[86/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.2, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.227291, 시간: 93.9초\n",
      "  모델 저장: model_h128_l7_d0.2_b32.pth\n",
      "진행률: 17.9% | 예상 남은 시간: 442.5분\n",
      "\n",
      "[87/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.2, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.209651, 시간: 43.9초\n",
      "  모델 저장: model_h128_l7_d0.2_b64.pth\n",
      "진행률: 18.1% | 예상 남은 시간: 439.6분\n",
      "\n",
      "[88/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.2, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.202676, 시간: 25.5초\n",
      "  모델 저장: model_h128_l7_d0.2_b128.pth\n",
      "진행률: 18.3% | 예상 남은 시간: 435.4분\n",
      "\n",
      "[89/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.3, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.331359, 시간: 172.2초\n",
      "  모델 저장: model_h128_l7_d0.3_b16.pth\n",
      "진행률: 18.5% | 예상 남은 시간: 442.1분\n",
      "\n",
      "[90/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.3, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.281655, 시간: 90.2초\n",
      "  모델 저장: model_h128_l7_d0.3_b32.pth\n",
      "진행률: 18.8% | 예상 남은 시간: 442.5분\n",
      "\n",
      "[91/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.3, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.266957, 시간: 51.8초\n",
      "  모델 저장: model_h128_l7_d0.3_b64.pth\n",
      "진행률: 19.0% | 예상 남은 시간: 440.2분\n",
      "\n",
      "[92/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.3, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.268888, 시간: 25.5초\n",
      "  모델 저장: model_h128_l7_d0.3_b128.pth\n",
      "진행률: 19.2% | 예상 남은 시간: 436.1분\n",
      "\n",
      "[93/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.4, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.384661, 시간: 171.2초\n",
      "  모델 저장: model_h128_l7_d0.4_b16.pth\n",
      "진행률: 19.4% | 예상 남은 시간: 442.2분\n",
      "\n",
      "[94/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.4, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.349637, 시간: 82.3초\n",
      "  모델 저장: model_h128_l7_d0.4_b32.pth\n",
      "진행률: 19.6% | 예상 남은 시간: 442.0분\n",
      "\n",
      "[95/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.4, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.311848, 시간: 43.6초\n",
      "  모델 저장: model_h128_l7_d0.4_b64.pth\n",
      "진행률: 19.8% | 예상 남은 시간: 439.2분\n",
      "\n",
      "[96/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.4, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.322671, 시간: 25.2초\n",
      "  모델 저장: model_h128_l7_d0.4_b128.pth\n",
      "진행률: 20.0% | 예상 남은 시간: 435.1분\n",
      "\n",
      "[97/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.5, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.446151, 시간: 158.0초\n",
      "  모델 저장: model_h128_l7_d0.5_b16.pth\n",
      "진행률: 20.2% | 예상 남은 시간: 439.9분\n",
      "\n",
      "[98/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.5, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.416826, 시간: 87.7초\n",
      "  모델 저장: model_h128_l7_d0.5_b32.pth\n",
      "진행률: 20.4% | 예상 남은 시간: 440.0분\n",
      "\n",
      "[99/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.5, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.372168, 시간: 55.6초\n",
      "  모델 저장: model_h128_l7_d0.5_b64.pth\n",
      "진행률: 20.6% | 예상 남은 시간: 438.0분\n",
      "\n",
      "[100/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 7, Dropout: 0.5, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.377959, 시간: 25.3초\n",
      "  모델 저장: model_h128_l7_d0.5_b128.pth\n",
      "진행률: 20.8% | 예상 남은 시간: 434.1분\n",
      "\n",
      "[101/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.1, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.277174, 시간: 173.8초\n",
      "  모델 저장: model_h128_l8_d0.1_b16.pth\n",
      "진행률: 21.0% | 예상 남은 시간: 439.5분\n",
      "\n",
      "[102/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.1, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.191964, 시간: 89.5초\n",
      "  모델 저장: model_h128_l8_d0.1_b32.pth\n",
      "진행률: 21.2% | 예상 남은 시간: 439.6분\n",
      "\n",
      "[103/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.1, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.179860, 시간: 46.3초\n",
      "  모델 저장: model_h128_l8_d0.1_b64.pth\n",
      "진행률: 21.5% | 예상 남은 시간: 437.0분\n",
      "\n",
      "[104/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.1, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.167754, 시간: 26.5초\n",
      "  모델 저장: model_h128_l8_d0.1_b128.pth\n",
      "진행률: 21.7% | 예상 남은 시간: 433.3분\n",
      "\n",
      "[105/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.2, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.309597, 시간: 220.7초\n",
      "  모델 저장: model_h128_l8_d0.2_b16.pth\n",
      "진행률: 21.9% | 예상 남은 시간: 441.1분\n",
      "\n",
      "[106/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.2, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.253766, 시간: 103.8초\n",
      "  모델 저장: model_h128_l8_d0.2_b32.pth\n",
      "진행률: 22.1% | 예상 남은 시간: 441.9분\n",
      "\n",
      "[107/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.2, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.233992, 시간: 56.9초\n",
      "  모델 저장: model_h128_l8_d0.2_b64.pth\n",
      "진행률: 22.3% | 예상 남은 시간: 439.9분\n",
      "\n",
      "[108/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.2, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.204667, 시간: 29.1초\n",
      "  모델 저장: model_h128_l8_d0.2_b128.pth\n",
      "진행률: 22.5% | 예상 남은 시간: 436.4분\n",
      "\n",
      "[109/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.3, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.350341, 시간: 193.7초\n",
      "  모델 저장: model_h128_l8_d0.3_b16.pth\n",
      "진행률: 22.7% | 예상 남은 시간: 442.2분\n",
      "\n",
      "[110/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.3, Batch Size: 32\n",
      "✓ 완료 - Test Loss: 0.305552, 시간: 131.5초\n",
      "  모델 저장: model_h128_l8_d0.3_b32.pth\n",
      "진행률: 22.9% | 예상 남은 시간: 444.3분\n",
      "\n",
      "[111/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.3, Batch Size: 64\n",
      "✓ 완료 - Test Loss: 0.286052, 시간: 68.8초\n",
      "  모델 저장: model_h128_l8_d0.3_b64.pth\n",
      "진행률: 23.1% | 예상 남은 시간: 443.0분\n",
      "\n",
      "[112/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.3, Batch Size: 128\n",
      "✓ 완료 - Test Loss: 0.296499, 시간: 37.5초\n",
      "  모델 저장: model_h128_l8_d0.3_b128.pth\n",
      "진행률: 23.3% | 예상 남은 시간: 439.9분\n",
      "\n",
      "[113/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.4, Batch Size: 16\n",
      "✓ 완료 - Test Loss: 0.401403, 시간: 180.4초\n",
      "  모델 저장: model_h128_l8_d0.4_b16.pth\n",
      "진행률: 23.5% | 예상 남은 시간: 444.6분\n",
      "\n",
      "[114/480] 테스트 중...\n",
      "Hidden Size: 128, Layers: 8, Dropout: 0.4, Batch Size: 32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 492\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m그리드 서치 완료! 모든 결과가 저장되었습니다. 🎯\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 492\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 472\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# 그리드 서치 실행\u001b[39;00m\n\u001b[1;32m    471\u001b[0m trainer \u001b[38;5;241m=\u001b[39m GridSearchTrainer(data_file, device)\n\u001b[0;32m--> 472\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_ranges\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.008\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# 결과 저장 및 분석\u001b[39;00m\n\u001b[1;32m    475\u001b[0m results_df \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39msave_results_table(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolynomial_grid_search_results.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 274\u001b[0m, in \u001b[0;36mGridSearchTrainer.grid_search\u001b[0;34m(self, config_ranges, epochs, lr)\u001b[0m\n\u001b[1;32m    271\u001b[0m config_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_single_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     config_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m config_start_time\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# 결과 저장\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 214\u001b[0m, in \u001b[0;36mGridSearchTrainer.train_single_config\u001b[0;34m(self, hidden_size, num_layers, dropout, batch_size, epochs, lr)\u001b[0m\n\u001b[1;32m    212\u001b[0m pred_roots \u001b[38;5;241m=\u001b[39m model(coeffs)\n\u001b[1;32m    213\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomplex_aware_loss(pred_roots, roots)\n\u001b[0;32m--> 214\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m    216\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "\n",
    "class PolynomialDataset(Dataset):\n",
    "    def __init__(self, data_file, train=True, train_ratio=0.8, normalize=True):\n",
    "        \"\"\"\n",
    "        저장된 데이터 파일로부터 Dataset 생성\n",
    "        \n",
    "        Args:\n",
    "            data_file: 데이터 파일 경로 (.json 또는 .pkl)\n",
    "            train: True면 훈련용, False면 테스트용\n",
    "            train_ratio: 훈련/테스트 분할 비율\n",
    "            normalize: 데이터 정규화 여부\n",
    "        \"\"\"\n",
    "        self.data = self.load_data(data_file)\n",
    "        self.normalize = normalize\n",
    "        self.coeffs, self.roots = self.prepare_data()\n",
    "        \n",
    "        # 정규화 파라미터 저장\n",
    "        if normalize:\n",
    "            self.coeff_mean = np.mean(self.coeffs, axis=0)\n",
    "            self.coeff_std = np.std(self.coeffs, axis=0) + 1e-8\n",
    "            self.root_mean = np.mean(self.roots, axis=0)\n",
    "            self.root_std = np.std(self.roots, axis=0) + 1e-8\n",
    "            \n",
    "            # 정규화 적용\n",
    "            self.coeffs = (self.coeffs - self.coeff_mean) / self.coeff_std\n",
    "            self.roots = (self.roots - self.root_mean) / self.root_std\n",
    "        \n",
    "        # 훈련/테스트 분할\n",
    "        train_coeffs, test_coeffs, train_roots, test_roots = train_test_split(\n",
    "            self.coeffs, self.roots, train_size=train_ratio, random_state=42\n",
    "        )\n",
    "        \n",
    "        if train:\n",
    "            self.coeffs = train_coeffs\n",
    "            self.roots = train_roots\n",
    "        else:\n",
    "            self.coeffs = test_coeffs\n",
    "            self.roots = test_roots\n",
    "        \n",
    "        print(f\"{'훈련' if train else '테스트'} 데이터셋: {len(self.coeffs)}개\")\n",
    "        if normalize:\n",
    "            print(f\"데이터 정규화 적용됨\")\n",
    "    \n",
    "    def load_data(self, filename):\n",
    "        \"\"\"데이터 파일 로드\"\"\"\n",
    "        if filename.endswith('.json'):\n",
    "            with open(filename, 'r', encoding='utf-8') as f:\n",
    "                return json.load(f)\n",
    "        elif filename.endswith('.pkl'):\n",
    "            with open(filename, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        else:\n",
    "            raise ValueError(\"지원하지 않는 파일 형식입니다. (.json 또는 .pkl 사용)\")\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        \"\"\"데이터를 학습용 형태로 변환\"\"\"\n",
    "        coeffs = []\n",
    "        roots = []\n",
    "        \n",
    "        for item in self.data:\n",
    "            coeffs.append(item['coefficients'])\n",
    "            \n",
    "            # 근 데이터 형식 확인 및 변환\n",
    "            item_roots = item['roots']\n",
    "            \n",
    "            if isinstance(item_roots[0], list):\n",
    "                # [[실수부, 허수부], ...] 형태를 [실수부1, 허수부1, ...] 형태로 평탄화\n",
    "                flattened_roots = []\n",
    "                for root in item_roots:\n",
    "                    flattened_roots.extend(root)\n",
    "                roots.append(flattened_roots)\n",
    "            else:\n",
    "                # 이미 [실수부1, 허수부1, ...] 형태\n",
    "                roots.append(item_roots)\n",
    "        \n",
    "        return np.array(coeffs, dtype=np.float32), np.array(roots, dtype=np.float32)\n",
    "    \n",
    "    def denormalize_roots(self, normalized_roots):\n",
    "        \"\"\"근을 원래 스케일로 되돌리기\"\"\"\n",
    "        if self.normalize and hasattr(self, 'root_mean'):\n",
    "            return normalized_roots * self.root_std + self.root_mean\n",
    "        return normalized_roots\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.coeffs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.FloatTensor(self.coeffs[idx]), torch.FloatTensor(self.roots[idx])\n",
    "\n",
    "class OptimizedPolynomialRootNet(nn.Module):\n",
    "    \"\"\"경량화된 효율적인 다항식 근 찾기 네트워크\"\"\"\n",
    "    def __init__(self, input_size=6, output_size=10, hidden_size=512, num_layers=4, dropout=0.3):\n",
    "        super(OptimizedPolynomialRootNet, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        current_size = input_size\n",
    "        \n",
    "        # 첫 번째 층\n",
    "        layers.extend([\n",
    "            nn.Linear(current_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Dropout(dropout)\n",
    "        ])\n",
    "        current_size = hidden_size\n",
    "        \n",
    "        # 중간 층들 (점진적 크기 감소)\n",
    "        for i in range(num_layers - 2):\n",
    "            next_size = hidden_size // (2 ** (i + 1))\n",
    "            next_size = max(next_size, 64)  # 최소 64개 뉴런\n",
    "            \n",
    "            layers.extend([\n",
    "                nn.Linear(current_size, next_size),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(next_size),\n",
    "                nn.Dropout(dropout * 0.8)  # 점진적으로 드롭아웃 감소\n",
    "            ])\n",
    "            current_size = next_size\n",
    "        \n",
    "        # 출력층\n",
    "        layers.append(nn.Linear(current_size, output_size))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # 가중치 초기화\n",
    "        self.apply(self._init_weights)\n",
    "    \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "            nn.init.constant_(module.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class GridSearchTrainer:\n",
    "    def __init__(self, data_file, device='cpu'):\n",
    "        self.data_file = data_file\n",
    "        self.device = device\n",
    "        self.results = []\n",
    "        \n",
    "        # 데이터셋 한 번만 로드 (매번 새로 로드하면 시간 소요)\n",
    "        print(\"데이터셋 로딩 중...\")\n",
    "        self.train_dataset = PolynomialDataset(data_file, train=True, normalize=True)\n",
    "        self.test_dataset = PolynomialDataset(data_file, train=False, normalize=True)\n",
    "        \n",
    "    def complex_aware_loss(self, pred_roots, true_roots, alpha=0.3):\n",
    "        \"\"\"복소수 근을 고려한 손실 함수\"\"\"\n",
    "        mse_loss = nn.MSELoss()(pred_roots, true_roots)\n",
    "        \n",
    "        pred_real = pred_roots[:, 0::2]\n",
    "        pred_imag = pred_roots[:, 1::2]\n",
    "        true_real = true_roots[:, 0::2]\n",
    "        true_imag = true_roots[:, 1::2]\n",
    "        \n",
    "        pred_magnitude = torch.sqrt(pred_real**2 + pred_imag**2)\n",
    "        true_magnitude = torch.sqrt(true_real**2 + true_imag**2)\n",
    "        magnitude_loss = nn.MSELoss()(pred_magnitude, true_magnitude)\n",
    "        \n",
    "        return (1 - alpha) * mse_loss + alpha * magnitude_loss\n",
    "    \n",
    "    def train_single_config(self, hidden_size, num_layers, dropout, batch_size, epochs=80, lr=0.008):\n",
    "        \"\"\"단일 구성으로 모델 훈련\"\"\"\n",
    "        \n",
    "        # 데이터 로더 생성\n",
    "        train_loader = DataLoader(self.train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "        test_loader = DataLoader(self.test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        # 모델 생성\n",
    "        model = OptimizedPolynomialRootNet(\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout\n",
    "        ).to(self.device)\n",
    "        \n",
    "        param_count = sum(p.numel() for p in model.parameters())\n",
    "        \n",
    "        # 옵티마이저 및 스케줄러\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode='min', factor=0.5, patience=10\n",
    "        )\n",
    "        \n",
    "        # 훈련 기록\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        best_test_loss = float('inf')\n",
    "        \n",
    "        # 훈련 루프\n",
    "        for epoch in range(epochs):\n",
    "            # 훈련\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            for coeffs, roots in train_loader:\n",
    "                coeffs, roots = coeffs.to(self.device), roots.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                pred_roots = model(coeffs)\n",
    "                loss = self.complex_aware_loss(pred_roots, roots)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                train_loss += loss.item()\n",
    "            \n",
    "            train_loss /= len(train_loader)\n",
    "            train_losses.append(train_loss)\n",
    "            \n",
    "            # 테스트\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for coeffs, roots in test_loader:\n",
    "                    coeffs, roots = coeffs.to(self.device), roots.to(self.device)\n",
    "                    pred_roots = model(coeffs)\n",
    "                    loss = self.complex_aware_loss(pred_roots, roots)\n",
    "                    test_loss += loss.item()\n",
    "            \n",
    "            test_loss /= len(test_loader)\n",
    "            test_losses.append(test_loss)\n",
    "            \n",
    "            scheduler.step(test_loss)\n",
    "            \n",
    "            if test_loss < best_test_loss:\n",
    "                best_test_loss = test_loss\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'param_count': param_count,\n",
    "            'best_test_loss': best_test_loss,\n",
    "            'final_train_loss': train_losses[-1],\n",
    "            'train_losses': train_losses,\n",
    "            'test_losses': test_losses\n",
    "        }\n",
    "    \n",
    "    def grid_search(self, config_ranges, epochs=80, lr=0.008):\n",
    "        \"\"\"그리드 서치 실행\"\"\"\n",
    "        \n",
    "        # 모든 조합 생성\n",
    "        combinations = list(itertools.product(\n",
    "            config_ranges['hidden_size'],\n",
    "            config_ranges['num_layers'],\n",
    "            config_ranges['dropout'],\n",
    "            config_ranges['batch_size']\n",
    "        ))\n",
    "        \n",
    "        total_combinations = len(combinations)\n",
    "        print(f\"총 {total_combinations}개의 조합을 테스트합니다.\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i, (hidden_size, num_layers, dropout, batch_size) in enumerate(combinations):\n",
    "            print(f\"\\n[{i+1}/{total_combinations}] 테스트 중...\")\n",
    "            print(f\"Hidden Size: {hidden_size}, Layers: {num_layers}, Dropout: {dropout}, Batch Size: {batch_size}\")\n",
    "            \n",
    "            config_start_time = time.time()\n",
    "            \n",
    "            try:\n",
    "                result = self.train_single_config(\n",
    "                    hidden_size=hidden_size,\n",
    "                    num_layers=num_layers,\n",
    "                    dropout=dropout,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    lr=lr\n",
    "                )\n",
    "                \n",
    "                config_time = time.time() - config_start_time\n",
    "                \n",
    "                # 결과 저장\n",
    "                config_result = {\n",
    "                    'config_id': i + 1,\n",
    "                    'hidden_size': hidden_size,\n",
    "                    'num_layers': num_layers,\n",
    "                    'dropout': dropout,\n",
    "                    'batch_size': batch_size,\n",
    "                    'param_count': result['param_count'],\n",
    "                    'best_test_loss': result['best_test_loss'],\n",
    "                    'final_train_loss': result['final_train_loss'],\n",
    "                    'training_time': config_time,\n",
    "                    'model_state_dict': result['model'].state_dict(),\n",
    "                    'train_losses': result['train_losses'],\n",
    "                    'test_losses': result['test_losses']\n",
    "                }\n",
    "                \n",
    "                self.results.append(config_result)\n",
    "                \n",
    "                # 모델 저장\n",
    "                model_filename = f\"model_h{hidden_size}_l{num_layers}_d{dropout:.1f}_b{batch_size}.pth\"\n",
    "                torch.save({\n",
    "                    'model_state_dict': result['model'].state_dict(),\n",
    "                    'config': config_result,\n",
    "                    'model_architecture': {\n",
    "                        'hidden_size': hidden_size,\n",
    "                        'num_layers': num_layers,\n",
    "                        'dropout': dropout\n",
    "                    }\n",
    "                }, model_filename)\n",
    "                \n",
    "                print(f\"✓ 완료 - Test Loss: {result['best_test_loss']:.6f}, 시간: {config_time:.1f}초\")\n",
    "                print(f\"  모델 저장: {model_filename}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"✗ 오류 발생: {str(e)}\")\n",
    "                continue\n",
    "            \n",
    "            # 진행률 및 예상 시간\n",
    "            elapsed_time = time.time() - start_time\n",
    "            avg_time_per_config = elapsed_time / (i + 1)\n",
    "            remaining_configs = total_combinations - (i + 1)\n",
    "            estimated_remaining_time = avg_time_per_config * remaining_configs\n",
    "            \n",
    "            print(f\"진행률: {(i+1)/total_combinations*100:.1f}% | \"\n",
    "                  f\"예상 남은 시간: {estimated_remaining_time/60:.1f}분\")\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"\\n그리드 서치 완료! 총 시간: {total_time/3600:.2f}시간\")\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def save_results_table(self, filename=\"grid_search_results.csv\"):\n",
    "        \"\"\"결과를 CSV 테이블로 저장\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"저장할 결과가 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        # DataFrame 생성용 데이터\n",
    "        table_data = []\n",
    "        for result in self.results:\n",
    "            table_data.append({\n",
    "                'Config_ID': result['config_id'],\n",
    "                'Hidden_Size': result['hidden_size'],\n",
    "                'Num_Layers': result['num_layers'],\n",
    "                'Dropout': result['dropout'],\n",
    "                'Batch_Size': result['batch_size'],\n",
    "                'Parameters': result['param_count'],\n",
    "                'Best_Test_Loss': result['best_test_loss'],\n",
    "                'Final_Train_Loss': result['final_train_loss'],\n",
    "                'Overfitting_Gap': result['final_train_loss'] - result['best_test_loss'],\n",
    "                'Training_Time_Min': result['training_time'] / 60\n",
    "            })\n",
    "        \n",
    "        df = pd.DataFrame(table_data)\n",
    "        \n",
    "        # 성능 순으로 정렬\n",
    "        df = df.sort_values('Best_Test_Loss')\n",
    "        df = df.reset_index(drop=True)\n",
    "        df['Rank'] = range(1, len(df) + 1)\n",
    "        \n",
    "        # CSV 저장\n",
    "        df.to_csv(filename, index=False)\n",
    "        print(f\"결과 테이블 저장: {filename}\")\n",
    "        \n",
    "        # 상위 10개 결과 출력\n",
    "        print(\"\\n=== 상위 10개 결과 ===\")\n",
    "        print(df.head(10).to_string(index=False))\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def plot_results_analysis(self):\n",
    "        \"\"\"결과 분석 시각화\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"분석할 결과가 없습니다.\")\n",
    "            return\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        \n",
    "        # 데이터 준비\n",
    "        hidden_sizes = [r['hidden_size'] for r in self.results]\n",
    "        num_layers = [r['num_layers'] for r in self.results]\n",
    "        dropouts = [r['dropout'] for r in self.results]\n",
    "        batch_sizes = [r['batch_size'] for r in self.results]\n",
    "        test_losses = [r['best_test_loss'] for r in self.results]\n",
    "        param_counts = [r['param_count'] for r in self.results]\n",
    "        \n",
    "        # 1. Hidden Size vs Test Loss\n",
    "        axes[0,0].scatter(hidden_sizes, test_losses, alpha=0.7)\n",
    "        axes[0,0].set_xlabel('Hidden Size')\n",
    "        axes[0,0].set_ylabel('Best Test Loss')\n",
    "        axes[0,0].set_title('Hidden Size vs Performance')\n",
    "        axes[0,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Num Layers vs Test Loss\n",
    "        axes[0,1].scatter(num_layers, test_losses, alpha=0.7)\n",
    "        axes[0,1].set_xlabel('Number of Layers')\n",
    "        axes[0,1].set_ylabel('Best Test Loss')\n",
    "        axes[0,1].set_title('Network Depth vs Performance')\n",
    "        axes[0,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Dropout vs Test Loss\n",
    "        axes[0,2].scatter(dropouts, test_losses, alpha=0.7)\n",
    "        axes[0,2].set_xlabel('Dropout Rate')\n",
    "        axes[0,2].set_ylabel('Best Test Loss')\n",
    "        axes[0,2].set_title('Dropout Rate vs Performance')\n",
    "        axes[0,2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Batch Size vs Test Loss\n",
    "        axes[1,0].scatter(batch_sizes, test_losses, alpha=0.7)\n",
    "        axes[1,0].set_xlabel('Batch Size')\n",
    "        axes[1,0].set_ylabel('Best Test Loss')\n",
    "        axes[1,0].set_title('Batch Size vs Performance')\n",
    "        axes[1,0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. Parameters vs Test Loss\n",
    "        axes[1,1].scatter(param_counts, test_losses, alpha=0.7)\n",
    "        axes[1,1].set_xlabel('Number of Parameters')\n",
    "        axes[1,1].set_ylabel('Best Test Loss')\n",
    "        axes[1,1].set_title('Model Size vs Performance')\n",
    "        axes[1,1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 6. Best configurations 히트맵\n",
    "        best_configs = sorted(self.results, key=lambda x: x['best_test_loss'])[:10]\n",
    "        config_names = [f\"H{c['hidden_size']}_L{c['num_layers']}_D{c['dropout']:.1f}_B{c['batch_size']}\" \n",
    "                       for c in best_configs]\n",
    "        losses = [c['best_test_loss'] for c in best_configs]\n",
    "        \n",
    "        axes[1,2].barh(range(len(config_names)), losses)\n",
    "        axes[1,2].set_yticks(range(len(config_names)))\n",
    "        axes[1,2].set_yticklabels(config_names, fontsize=8)\n",
    "        axes[1,2].set_xlabel('Best Test Loss')\n",
    "        axes[1,2].set_title('Top 10 Configurations')\n",
    "        axes[1,2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('grid_search_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "def main():\n",
    "    # 설정\n",
    "    data_file = \"polynomial_dataset_sorted.json\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"사용 디바이스: {device}\")\n",
    "    \n",
    "    if not os.path.exists(data_file):\n",
    "        print(f\"데이터 파일을 찾을 수 없습니다: {data_file}\")\n",
    "        return\n",
    "    \n",
    "    # 그리드 서치 범위 정의\n",
    "    # 128*4, 128*5, 128*6, 128*7, 128*8, 128*9, 128*10, 128*11, 128*12\n",
    "    config_ranges = {\n",
    "        'hidden_size': [128*1, 128*2, 128*3],\n",
    "        'num_layers': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        'dropout': [0.1, 0.2, 0.3],\n",
    "        'batch_size': [16, 32, 64, 128]\n",
    "    }\n",
    "    \n",
    "    print(\"그리드 서치 범위:\")\n",
    "    for key, values in config_ranges.items():\n",
    "        print(f\"  {key}: {values}\")\n",
    "    \n",
    "    total_combinations = 1\n",
    "    for values in config_ranges.values():\n",
    "        total_combinations *= len(values)\n",
    "    print(f\"총 조합 수: {total_combinations}\")\n",
    "    \n",
    "    # 그리드 서치 실행\n",
    "    trainer = GridSearchTrainer(data_file, device)\n",
    "    results = trainer.grid_search(config_ranges, epochs=80, lr=0.008)\n",
    "    \n",
    "    # 결과 저장 및 분석\n",
    "    results_df = trainer.save_results_table(\"polynomial_grid_search_results.csv\")\n",
    "    trainer.plot_results_analysis()\n",
    "    \n",
    "    # 최고 성능 모델 정보\n",
    "    if results:\n",
    "        best_result = min(results, key=lambda x: x['best_test_loss'])\n",
    "        print(f\"\\n🏆 최고 성능 모델:\")\n",
    "        print(f\"  Hidden Size: {best_result['hidden_size']}\")\n",
    "        print(f\"  Num Layers: {best_result['num_layers']}\")\n",
    "        print(f\"  Dropout: {best_result['dropout']}\")\n",
    "        print(f\"  Batch Size: {best_result['batch_size']}\")\n",
    "        print(f\"  Best Test Loss: {best_result['best_test_loss']:.6f}\")\n",
    "        print(f\"  Parameters: {best_result['param_count']:,}\")\n",
    "    \n",
    "    print(\"\\n그리드 서치 완료! 모든 결과가 저장되었습니다. 🎯\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6a5dc2-2a38-495d-979b-0b7fbf9a42e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
